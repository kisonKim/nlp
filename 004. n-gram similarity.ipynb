{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0077c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#n gram 유사도\n",
    "# 두 문장간의 유사도를 계산함.\n",
    "\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "\n",
    "def word_ngram(bow,num_gram):\n",
    "    text = tuple(bow)\n",
    "    ngrams = [text[x:x+ num_gram] for x in range(0, len(text))]\n",
    "    return tuple(ngrams)\n",
    "\n",
    "def similarity(doc1,doc2):\n",
    "    cnt = 0\n",
    "    for token in doc1:\n",
    "        if token in doc2:\n",
    "            cnt += 1\n",
    "    return cnt/len(doc1)\n",
    "            \n",
    "sentence_1 = \"6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다.\"\n",
    "sentence_2 = \"6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다.\"\n",
    "\n",
    "kom = Komoran()\n",
    "\n",
    "#bow(ag of words) :: n-gram으로 만들어진 토큰의 집합\n",
    "bow_1 = kom.nouns(sentence_1)\n",
    "bow_2 = kom.nouns(sentence_2)\n",
    "\n",
    "print(similarity(word_ngram(bow_1,2), word_ngram(bow_2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b7903faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "array = ['6월', '뉴턴', '선생님', '제안', '트리니티', '입학', '6월', '뉴턴', '선생님', '제안', '대학교', '입학']\n",
    "target = ['6월', '뉴턴', '선생님', '제안']\n",
    "temp = [0 for _ in range(0,len(array))]\n",
    "for index,value in enumerate(array):\n",
    "    if value in target:\n",
    "        temp[index]=1;\n",
    "print(temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c817e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "944594f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#ngram  2번째 구현\n",
    "#두 문장의 유사도를 통계적으로 파악하는 방법\n",
    "#토큰을 몇개씩 묶어서 비교할거냐에 따라 n의 숫자가 달라짐\n",
    "\n",
    "\n",
    "\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "\n",
    "def word_ngram(bow,num_gram):\n",
    "    text = tuple(bow)\n",
    "    ngrams = [text[x:x+ num_gram] for x in range(0, len(text))]\n",
    "    return tuple(ngrams)\n",
    "\n",
    "def similarity(doc1,doc2):\n",
    "    cnt = 0\n",
    "    for token in doc1:\n",
    "        if token in doc2:\n",
    "            cnt += 1\n",
    "    return cnt/len(doc1)\n",
    "    \n",
    "komoran = Komoran()\n",
    "\n",
    "sentence_1 = \"6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다.\"\n",
    "sentence_2 = \"6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다.\"\n",
    "sentence_3 = \"6월은 나의 생일이자 대학교 입학날이기도 하다.\"\n",
    "\n",
    "\n",
    "#단어추출\n",
    "nouns1 = komoran.nouns(sentence_1)\n",
    "nouns2 = komoran.nouns(sentence_2)\n",
    "\n",
    "#두개씩 묶기\n",
    "print(similarity(word_ngram(nouns1, 2),word_ngram(nouns2,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "404b9ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ngram 3번째 구현 (2021-11-16)\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "def ngram_corpus(arr,ngram_num):\n",
    "    texts = tuple(arr)\n",
    "    ngrams = [ texts[i:i+ngram_num] for i in range(0,len(arr))]\n",
    "    return ngrams\n",
    "\n",
    "def ngram_similarity(arr1,arr2):\n",
    "    count = 0\n",
    "    for token in arr1:\n",
    "        if token in arr2:\n",
    "            count+=1\n",
    "    return count/len(arr1)\n",
    "komoran = Komoran()\n",
    "sentence_1 = \"6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다.\"\n",
    "sentence_2 = \"6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다.\"\n",
    "\n",
    "noun_1 = komoran.nouns(sentence_1)\n",
    "noun_2 = komoran.nouns(sentence_2)\n",
    "\n",
    "corpus1 = ngram_corpus(noun_1, 2) #bi-gram으로\n",
    "corpus2 = ngram_corpus(noun_2, 2)\n",
    "\n",
    "ngram_similarity(corpus1,corpus2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f928b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe1981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded6cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa679fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
